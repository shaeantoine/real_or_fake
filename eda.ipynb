{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c48803c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "This notebook will explore the dataset provided for the purposes of feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e100e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6626b",
   "metadata": {},
   "source": [
    "### Fetching training data from local store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "745c2fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                             file_1  \\\n",
      "0           0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
      "1           1  China\\nThe goal of this project involves achie...   \n",
      "2           2  Scientists can learn about how galaxies form a...   \n",
      "3           3  China\\nThe study suggests that multiple star s...   \n",
      "4           4  Dinosaur Rex was excited about his new toy set...   \n",
      "\n",
      "                                              file_2  real_file_label  \n",
      "0  The China relay network has released a signifi...                2  \n",
      "1  The project aims to achieve an accuracy level ...                1  \n",
      "2  Dinosaur eggshells offer clues about what dino...                2  \n",
      "3  The importance for understanding how stars evo...                2  \n",
      "4  Analyzing how fast stars rotate within a galax...                1  \n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"data/train_df.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bad195",
   "metadata": {},
   "source": [
    "### Identifying missing values\n",
    "\n",
    "The code below will also replace these missing values with empty strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da6c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = train_df.copy()\n",
    "\n",
    "# Method 1: Replacing NaNs with empty strings\n",
    "# for idx, row in clean_df.iterrows():\n",
    "#     if pd.isna(row[\"file_1\"]):\n",
    "#         print(row)\n",
    "#         clean_df.at[idx, \"file_1\"] = \"\"\n",
    "#     elif pd.isna(row[\"file_2\"]):\n",
    "#         print(row)\n",
    "#         clean_df.at[idx, \"file_2\"] = \"\"\n",
    "\n",
    "# Method 2: Removing NA rows altogether \n",
    "clean_df.dropna(subset=[\"file_1\", \"file_2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb40eb9a",
   "metadata": {},
   "source": [
    "### Extract Basic Data Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d130da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_features(df):\n",
    "    # Create real and fake text columns\n",
    "    df['real_text'] = df.apply(\n",
    "        lambda row: row['file_1'] if row['real_file_label'] == 1 else row['file_2'], \n",
    "        axis=1\n",
    "    )\n",
    "    df['fake_text'] = df.apply(\n",
    "        lambda row: row['file_2'] if row['real_file_label'] == 1 else row['file_1'], \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        real_text = row['real_text']\n",
    "        fake_text = row['fake_text']\n",
    "        \n",
    "        # Basic length features\n",
    "        real_chars = len(real_text)\n",
    "        fake_chars = len(fake_text)\n",
    "        real_words = len(real_text.split())\n",
    "        fake_words = len(fake_text.split())\n",
    "        \n",
    "        # Basic punctuation features\n",
    "        real_punct = len(re.findall(r'[.!?,:;]', real_text))\n",
    "        fake_punct = len(re.findall(r'[.!?,:;]', fake_text))\n",
    "        \n",
    "        # Basic sentence features\n",
    "        real_sents = len([s for s in re.split(r'[.!?]+', real_text) if s.strip()])\n",
    "        fake_sents = len([s for s in re.split(r'[.!?]+', fake_text) if s.strip()])\n",
    "        \n",
    "        # Basic variance features\n",
    "        real_word_lengths = [len(w) for w in real_text.split()] if real_words > 0 else [0]\n",
    "        fake_word_lengths = [len(w) for w in fake_text.split()] if fake_words > 0 else [0]\n",
    "        real_word_var = np.var(real_word_lengths) if len(real_word_lengths) > 1 else 0\n",
    "        fake_word_var = np.var(fake_word_lengths) if len(fake_word_lengths) > 1 else 0\n",
    "        \n",
    "        # Count proper nouns\n",
    "        real_proper = len([w for i, w in enumerate(real_text.split()) \n",
    "                            if w and w[0].isupper() and i > 0])\n",
    "        fake_proper = len([w for i, w in enumerate(fake_text.split()) \n",
    "                            if w and w[0].isupper() and i > 0])\n",
    "        \n",
    "        # Numbers\n",
    "        real_numbers = len(re.findall(r'\\d+', real_text))\n",
    "        fake_numbers = len(re.findall(r'\\d+', fake_text))\n",
    "        \n",
    "        feature_row = {\n",
    "            # Length differences\n",
    "            'char_real': real_chars,\n",
    "            'char_fake': fake_chars,\n",
    "            'word_real': real_words,\n",
    "            'word_fake': fake_words,\n",
    "            'char_diff': real_chars - fake_chars,\n",
    "            'word_diff': real_words - fake_words,\n",
    "            'char_ratio': real_chars / (fake_chars + 1) if fake_chars > 0 else real_chars,\n",
    "            'word_ratio': real_words / (fake_words + 1) if fake_words > 0 else real_words,\n",
    "            \n",
    "            # Punctuation differences  \n",
    "            'punct_real': real_punct,\n",
    "            'punct_fake': fake_punct, \n",
    "            'punct_diff': real_punct - fake_punct,\n",
    "            'punct_density_real': real_punct / (real_words + 1),\n",
    "            'punct_density_fake': fake_punct / (fake_words + 1),\n",
    "            'punct_density_diff': (real_punct / (real_words + 1)) - (fake_punct / (fake_words + 1)),\n",
    "            \n",
    "            # Sentence differences\n",
    "            'real_sent': real_sents,\n",
    "            'fake_sent': fake_sents,\n",
    "            'sent_diff': real_sents - fake_sents,\n",
    "            'sent_ratio': real_sents / (fake_sents + 1) if fake_sents > 0 else real_sents,\n",
    "            \n",
    "            # Variance differences\n",
    "            'word_var_real': real_word_var,\n",
    "            'word_var_fake': fake_word_var,\n",
    "            'word_var_diff': real_word_var - fake_word_var,\n",
    "            \n",
    "            # Content differences\n",
    "            'real_proper': real_proper,\n",
    "            'fake_proper': fake_proper,\n",
    "            'proper_diff': real_proper - fake_proper,\n",
    "            'proper_density_real': real_proper / (real_words + 1),\n",
    "            'proper_density_fake': fake_proper / (fake_words + 1),\n",
    "            'real_numbers': real_numbers,\n",
    "            'fake_numbers': fake_numbers,\n",
    "            'numbers_diff': real_numbers - fake_numbers,\n",
    "        }\n",
    "        \n",
    "        features.append(feature_row)\n",
    "\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4df02e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = extract_basic_features(df_fill)\n",
    "labels = (df_fill['real_file_label'] - 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c495d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   char_real  char_fake  word_real  word_fake  char_diff  word_diff  \\\n",
      "0       2018       2196        296        304       -178         -8   \n",
      "1       3124        936        454        137       2188        317   \n",
      "2        801       1139        125        159       -338        -34   \n",
      "3       1869       1774        262        263         95         -1   \n",
      "4        195        871         34        123       -676        -89   \n",
      "\n",
      "   char_ratio  word_ratio  punct_real  punct_fake  ...  word_var_fake  \\\n",
      "0    0.918525    0.970492          18          16  ...       8.116246   \n",
      "1    3.334045    3.289855          17          11  ...       9.229687   \n",
      "2    0.702632    0.781250           4           9  ...       7.398837   \n",
      "3    1.052958    0.992424          11          16  ...       8.096720   \n",
      "4    0.223624    0.274194           6           7  ...       9.365986   \n",
      "\n",
      "   word_var_diff  real_proper  fake_proper  proper_diff  proper_density_real  \\\n",
      "0      -0.070604           20           38          -18             0.067340   \n",
      "1      -0.950364           17            6           11             0.037363   \n",
      "2      -0.531893            6            3            3             0.047619   \n",
      "3       0.663026           12           31          -19             0.045627   \n",
      "4      -2.715467            4            3            1             0.114286   \n",
      "\n",
      "   proper_density_fake  real_numbers  fake_numbers  numbers_diff  \n",
      "0             0.124590             0             0             0  \n",
      "1             0.043478             1             6            -5  \n",
      "2             0.018750             1             0             1  \n",
      "3             0.117424             0             0             0  \n",
      "4             0.024194             0             1            -1  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6af54ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         char_real     char_fake    word_real    word_fake     char_diff  \\\n",
      "count    94.000000     94.000000    94.000000    94.000000     94.000000   \n",
      "mean   2311.106383   2566.595745   311.319149   333.606383   -255.489362   \n",
      "std    2203.397184   4486.382489   227.145456   458.380464   5115.865186   \n",
      "min      69.000000      0.000000     9.000000     0.000000 -38648.000000   \n",
      "25%    1274.000000   1118.000000   186.250000   167.000000   -610.000000   \n",
      "50%    1655.000000   1437.500000   245.000000   216.500000     83.000000   \n",
      "75%    2122.750000   2072.750000   327.000000   314.750000    735.250000   \n",
      "max    9561.000000  40316.000000  1008.000000  4158.000000   8521.000000   \n",
      "\n",
      "         word_diff   char_ratio  word_ratio  punct_real  punct_fake  ...  \\\n",
      "count    94.000000    94.000000   94.000000   94.000000   94.000000  ...   \n",
      "mean    -22.287234    40.317063    6.746286   37.287234   41.968085  ...   \n",
      "std     518.453648   264.231546   36.385037   41.809507   74.349285  ...   \n",
      "min   -3902.000000     0.041372    0.047619    1.000000    0.000000  ...   \n",
      "25%     -88.750000     0.660164    0.664663   16.000000   15.000000  ...   \n",
      "50%      10.500000     1.065159    1.039387   24.000000   22.000000  ...   \n",
      "75%     115.500000     1.676675    1.752891   36.500000   34.750000  ...   \n",
      "max     826.000000  1857.000000  257.000000  178.000000  633.000000  ...   \n",
      "\n",
      "       word_var_fake  word_var_diff  real_proper  fake_proper  proper_diff  \\\n",
      "count      94.000000      94.000000    94.000000    94.000000    94.000000   \n",
      "mean       12.160924       0.154395    37.010638    43.691489    -6.680851   \n",
      "std         8.998122      13.066774    38.041713    75.413559    83.755560   \n",
      "min         0.000000     -31.698770     4.000000     0.000000  -667.000000   \n",
      "25%         8.373442      -0.952744    16.000000    15.500000    -8.000000   \n",
      "50%         9.370277       0.077235    25.000000    28.000000     0.000000   \n",
      "75%        10.697244       1.073054    35.500000    42.500000     9.750000   \n",
      "max        40.408251      36.047159   181.000000   680.000000   123.000000   \n",
      "\n",
      "       proper_density_real  proper_density_fake  real_numbers  fake_numbers  \\\n",
      "count            94.000000            94.000000     94.000000     94.000000   \n",
      "mean              0.118367             0.119270      7.765957      7.500000   \n",
      "std               0.080007             0.061446      8.600357      9.050337   \n",
      "min               0.028777             0.000000      0.000000      0.000000   \n",
      "25%               0.072359             0.087310      1.000000      1.250000   \n",
      "50%               0.101409             0.115296      6.000000      5.500000   \n",
      "75%               0.141637             0.143569     12.750000     12.000000   \n",
      "max               0.600000             0.360577     45.000000     67.000000   \n",
      "\n",
      "       numbers_diff  \n",
      "count     94.000000  \n",
      "mean       0.265957  \n",
      "std        8.466475  \n",
      "min      -51.000000  \n",
      "25%       -1.000000  \n",
      "50%        0.000000  \n",
      "75%        1.000000  \n",
      "max       38.000000  \n",
      "\n",
      "[8 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db5c6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_diff:\n",
      "  Real (file_1): 820.3333\n",
      "  Fake (file_2): -1243.4898\n",
      "  Difference: 2063.8231\n",
      "\n",
      "word_diff:\n",
      "  Real (file_1): 94.4889\n",
      "  Fake (file_2): -129.5306\n",
      "  Difference: 224.0195\n",
      "\n",
      "char_ratio:\n",
      "  Real (file_1): 43.2404\n",
      "  Fake (file_2): 37.6324\n",
      "  Difference: 5.6080\n",
      "\n",
      "word_ratio:\n",
      "  Real (file_1): 7.4773\n",
      "  Fake (file_2): 6.0750\n",
      "  Difference: 1.4023\n",
      "\n",
      "punct_diff:\n",
      "  Real (file_1): 12.8667\n",
      "  Fake (file_2): -20.7959\n",
      "  Difference: 33.6626\n",
      "\n",
      "punct_density_real:\n",
      "  Real (file_1): 0.1061\n",
      "  Fake (file_2): 0.1043\n",
      "  Difference: 0.0018\n",
      "\n",
      "punct_density_fake:\n",
      "  Real (file_1): 0.0947\n",
      "  Fake (file_2): 0.1073\n",
      "  Difference: -0.0125\n",
      "\n",
      "punct_density_diff:\n",
      "  Real (file_1): 0.0114\n",
      "  Fake (file_2): -0.0030\n",
      "  Difference: 0.0144\n",
      "\n",
      "sent_diff:\n",
      "  Real (file_1): 5.1111\n",
      "  Fake (file_2): -9.7755\n",
      "  Difference: 14.8866\n",
      "\n",
      "sent_ratio:\n",
      "  Real (file_1): 1.9842\n",
      "  Fake (file_2): 1.2083\n",
      "  Difference: 0.7758\n",
      "\n",
      "word_var_real:\n",
      "  Real (file_1): 13.2514\n",
      "  Fake (file_2): 11.4557\n",
      "  Difference: 1.7958\n",
      "\n",
      "word_var_fake:\n",
      "  Real (file_1): 11.2089\n",
      "  Fake (file_2): 13.0352\n",
      "  Difference: -1.8264\n",
      "\n",
      "word_var_diff:\n",
      "  Real (file_1): 2.0425\n",
      "  Fake (file_2): -1.5796\n",
      "  Difference: 3.6221\n",
      "\n",
      "proper_diff:\n",
      "  Real (file_1): 8.8889\n",
      "  Fake (file_2): -20.9796\n",
      "  Difference: 29.8685\n",
      "\n",
      "proper_density_real:\n",
      "  Real (file_1): 0.1108\n",
      "  Fake (file_2): 0.1253\n",
      "  Difference: -0.0146\n",
      "\n",
      "proper_density_fake:\n",
      "  Real (file_1): 0.1206\n",
      "  Fake (file_2): 0.1181\n",
      "  Difference: 0.0025\n",
      "\n",
      "numbers_diff:\n",
      "  Real (file_1): 0.5333\n",
      "  Fake (file_2): 0.0204\n",
      "  Difference: 0.5129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_feature_distributions(features_df, labels):    \n",
    "    for feature in features_df.columns:\n",
    "        real_vals = features_df[labels == 0][feature]\n",
    "        fake_vals = features_df[labels == 1][feature]\n",
    "        \n",
    "        real_mean = real_vals.mean()\n",
    "        fake_mean = fake_vals.mean()\n",
    "        diff = real_mean - fake_mean\n",
    "        \n",
    "        print(f\"{feature}:\")\n",
    "        print(f\"  Real: {real_mean:.4f}\")\n",
    "        print(f\"  Fake: {fake_mean:.4f}\")\n",
    "        print(f\"  Difference: {diff:.4f}\")\n",
    "        print()\n",
    "\n",
    "analyze_feature_distributions(features_df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
