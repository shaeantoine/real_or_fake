{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c48803c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "This notebook will explore the dataset provided for the purposes of feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58e100e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6626b",
   "metadata": {},
   "source": [
    "### Fetching training data from local store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "745c2fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                             file_1  \\\n",
      "0           0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
      "1           1  China\\nThe goal of this project involves achie...   \n",
      "2           2  Scientists can learn about how galaxies form a...   \n",
      "3           3  China\\nThe study suggests that multiple star s...   \n",
      "4           4  Dinosaur Rex was excited about his new toy set...   \n",
      "\n",
      "                                              file_2  real_file_label  \n",
      "0  The China relay network has released a signifi...                2  \n",
      "1  The project aims to achieve an accuracy level ...                1  \n",
      "2  Dinosaur eggshells offer clues about what dino...                2  \n",
      "3  The importance for understanding how stars evo...                2  \n",
      "4  Analyzing how fast stars rotate within a galax...                1  \n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"data/train_df.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bad195",
   "metadata": {},
   "source": [
    "### Identifying missing values\n",
    "\n",
    "I have implemented two options, first is to replace the NA values with an empty string. The second is to drop the observation all together.\n",
    "\n",
    "Importantly from the output below there are two rows that have NAs. Both rows have missing fake texts. Since the sample size is already small, injecting empty strings may influence performance of the algorithms more than removing the samples altogether. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da6c707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples before data cleaning: 94\n",
      "Unnamed: 0                                                        10\n",
      "file_1             To determine how old stars are within R136's c...\n",
      "file_2                                                           NaN\n",
      "real_file_label                                                    1\n",
      "Name: 10, dtype: object\n",
      "Unnamed: 0                                                        14\n",
      "file_1                                                           NaN\n",
      "file_2             The design phase for CTAs (the Cherenkov Teles...\n",
      "real_file_label                                                    2\n",
      "Name: 14, dtype: object\n",
      "Number of samples before data cleaning: 92\n"
     ]
    }
   ],
   "source": [
    "clean_df = train_df.copy()\n",
    "print(f\"Number of samples before data cleaning: {len(clean_df)}\")\n",
    "\n",
    "# Method 1: Replacing NaNs with empty strings\n",
    "for idx, row in clean_df.iterrows():\n",
    "    if pd.isna(row[\"file_1\"]):\n",
    "        print(row)\n",
    "        # clean_df.at[idx, \"file_1\"] = \"\"\n",
    "    elif pd.isna(row[\"file_2\"]):\n",
    "        print(row)\n",
    "        # clean_df.at[idx, \"file_2\"] = \"\"\n",
    "\n",
    "# Method 2: Removing NA rows altogether \n",
    "clean_df.dropna(subset=[\"file_1\", \"file_2\"], inplace=True)\n",
    "print(f\"Number of samples before data cleaning: {len(clean_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb40eb9a",
   "metadata": {},
   "source": [
    "### Extract Basic Data Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d130da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_features(df):\n",
    "    # Create real and fake text columns\n",
    "    df['real_text'] = df.apply(\n",
    "        lambda row: row['file_1'] if row['real_file_label'] == 1 else row['file_2'], \n",
    "        axis=1\n",
    "    )\n",
    "    df['fake_text'] = df.apply(\n",
    "        lambda row: row['file_2'] if row['real_file_label'] == 1 else row['file_1'], \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        real_text = row['real_text']\n",
    "        fake_text = row['fake_text']\n",
    "        \n",
    "        # Basic length features\n",
    "        real_chars = len(real_text)\n",
    "        fake_chars = len(fake_text)\n",
    "        real_words = len(real_text.split())\n",
    "        fake_words = len(fake_text.split())\n",
    "        \n",
    "        # Basic punctuation features\n",
    "        real_punct = len(re.findall(r'[.!?,:;]', real_text))\n",
    "        fake_punct = len(re.findall(r'[.!?,:;]', fake_text))\n",
    "        real_punct_types = len(set(re.findall(r'[.!?,:;()]', real_text)))\n",
    "        fake_punct_types = len(set(re.findall(r'[.!?,:;()]', fake_text)))\n",
    "        \n",
    "        # Basic sentence features\n",
    "        real_sents = len([s for s in re.split(r'[.!?]+', real_text) if s.strip()])\n",
    "        fake_sents = len([s for s in re.split(r'[.!?]+', fake_text) if s.strip()])\n",
    "        #real_avg_sent_len = np.mean([len(s.split()) for s in real_sents]) if real_sents else 0\n",
    "        #fake_avg_sent_len = np.mean([len(s.split()) for s in fake_sents]) if fake_sents else 0\n",
    "        \n",
    "        # Basic variance features\n",
    "        real_word_lengths = [len(w) for w in real_text.split()] if real_words > 0 else [0]\n",
    "        fake_word_lengths = [len(w) for w in fake_text.split()] if fake_words > 0 else [0]\n",
    "        real_word_var = np.var(real_word_lengths) if len(real_word_lengths) > 1 else 0\n",
    "        fake_word_var = np.var(fake_word_lengths) if len(fake_word_lengths) > 1 else 0\n",
    "        \n",
    "        # Count proper nouns\n",
    "        real_proper = len([w for i, w in enumerate(real_text.split()) \n",
    "                            if w and w[0].isupper() and i > 0])\n",
    "        fake_proper = len([w for i, w in enumerate(fake_text.split()) \n",
    "                            if w and w[0].isupper() and i > 0])\n",
    "        \n",
    "        # Numbers\n",
    "        real_numbers = len(re.findall(r'\\d+', real_text))\n",
    "        fake_numbers = len(re.findall(r'\\d+', fake_text))\n",
    "        real_precise_nums = len([n for n in re.findall(r'\\d+\\.?\\d*', real_text) if '.' in n])\n",
    "        fake_precise_nums = len([n for n in re.findall(r'\\d+\\.?\\d*', fake_text) if '.' in n])\n",
    "        real_large_nums = len([n for n in re.findall(r'\\d+', real_text) if len(n) >= 3])\n",
    "        fake_large_nums = len([n for n in re.findall(r'\\d+', fake_text) if len(n) >= 3])\n",
    "\n",
    "        # Science terms\n",
    "        science_terms = ['telescope', 'survey', 'observation', 'stellar', 'galaxy', 'star', \n",
    "                'astronomical', 'magnitude', 'photometric', 'spectroscopic', \n",
    "                'wavelength', 'redshift', 'luminosity', 'parsec', 'light-year']\n",
    "\n",
    "        real_science_count = sum(1 for term in science_terms if term.lower() in real_text.lower())\n",
    "        fake_science_count = sum(1 for term in science_terms if term.lower() in fake_text.lower())\n",
    "\n",
    "        # Abbreviations\n",
    "        abbrevs = ['ESO', 'NASA', 'VLT', 'HST', 'ALMA', 'VISTA', 'VIRSA', 'VMC', 'VVV']\n",
    "        real_abbrev_count = sum(1 for abbrev in abbrevs if abbrev in real_text)\n",
    "        fake_abbrev_count = sum(1 for abbrev in abbrevs if abbrev in fake_text)\n",
    "\n",
    "        # Repetition patterns\n",
    "        real_word_freq = Counter(real_text.lower().split())\n",
    "        fake_word_freq = Counter(fake_text.lower().split())\n",
    "        real_repetition_score = sum(count for count in real_word_freq.values() if count > 1)\n",
    "        fake_repetition_score = sum(count for count in fake_word_freq.values() if count > 1)\n",
    "        real_unique_ratio = len(set(real_text.lower().split())) / (len(real_text.split()) + 1)\n",
    "        fake_unique_ratio = len(set(fake_text.lower().split())) / (len(fake_text.split()) + 1)\n",
    "        \n",
    "        feature_row = {\n",
    "            # Length differences\n",
    "            'char_real': real_chars,\n",
    "            'char_fake': fake_chars,\n",
    "            'word_real': real_words,\n",
    "            'word_fake': fake_words,\n",
    "            'char_diff': real_chars - fake_chars,\n",
    "            'word_diff': real_words - fake_words,\n",
    "            'char_ratio': real_chars / (fake_chars + 1) if fake_chars > 0 else real_chars,\n",
    "            'word_ratio': real_words / (fake_words + 1) if fake_words > 0 else real_words,\n",
    "            \n",
    "            # Punctuation differences  \n",
    "            'punct_real': real_punct,\n",
    "            'punct_fake': fake_punct, \n",
    "            'punct_diff': real_punct - fake_punct,\n",
    "            'real_punct_types': real_punct_types,\n",
    "            'fake_punct_types': fake_punct_types, \n",
    "            'punct_density_real': real_punct / (real_words + 1),\n",
    "            'punct_density_fake': fake_punct / (fake_words + 1),\n",
    "            'punct_density_diff': (real_punct / (real_words + 1)) - (fake_punct / (fake_words + 1)),\n",
    "            \n",
    "            # Sentence differences\n",
    "            'real_sent': real_sents,\n",
    "            'fake_sent': fake_sents,\n",
    "            'sent_diff': real_sents - fake_sents,\n",
    "            'sent_ratio': real_sents / (fake_sents + 1) if fake_sents > 0 else real_sents,\n",
    "            # 'real_avg_sent_len': real_avg_sent_len,\n",
    "            # 'fake_avg_sent_len': fake_avg_sent_len,\n",
    "\n",
    "            \n",
    "            # Variance differences\n",
    "            'word_var_real': real_word_var,\n",
    "            'word_var_fake': fake_word_var,\n",
    "            'word_var_diff': real_word_var - fake_word_var,\n",
    "            \n",
    "            # Content differences\n",
    "            'real_proper': real_proper,\n",
    "            'fake_proper': fake_proper,\n",
    "            'proper_diff': real_proper - fake_proper,\n",
    "            'proper_density_real': real_proper / (real_words + 1),\n",
    "            'proper_density_fake': fake_proper / (fake_words + 1),\n",
    "\n",
    "            # Numbers\n",
    "            'real_numbers': real_numbers,\n",
    "            'fake_numbers': fake_numbers,\n",
    "            'numbers_diff': real_numbers - fake_numbers,\n",
    "            'real_precise_nums': real_precise_nums,\n",
    "            'fake_precise_nums': fake_precise_nums,\n",
    "            'real_large_nums': real_large_nums,\n",
    "            'fake_large_nums': fake_large_nums,\n",
    "\n",
    "            # Science terms\n",
    "            'real_science_count': real_science_count,\n",
    "            'fake_science_count': fake_science_count,\n",
    "\n",
    "            # Abbreviations\n",
    "            'real_abbrev_count': real_abbrev_count,\n",
    "            'fake_abbrev_count': fake_abbrev_count,\n",
    "\n",
    "            # Repetition patterns\n",
    "            'real_repetition_score': real_repetition_score,\n",
    "            'fake_repetition_score': fake_repetition_score,\n",
    "            'real_unique_ratio': real_unique_ratio,\n",
    "            'fake_unique_ratio': fake_unique_ratio\n",
    "        }\n",
    "        \n",
    "        features.append(feature_row)\n",
    "\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4df02e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         char_real     char_fake    word_real    word_fake     char_diff  \\\n",
      "count    92.000000     92.000000    92.000000    92.000000     92.000000   \n",
      "mean   2321.728261   2622.391304   312.608696   340.858696   -300.663043   \n",
      "std    2226.269161   4519.078181   229.454679   460.685719   5162.392454   \n",
      "min      69.000000    285.000000     9.000000    32.000000 -38648.000000   \n",
      "25%    1264.750000   1132.250000   184.250000   170.750000   -643.750000   \n",
      "50%    1631.000000   1442.000000   242.000000   218.500000     75.500000   \n",
      "75%    2158.750000   2091.750000   333.000000   320.250000    688.750000   \n",
      "max    9561.000000  40316.000000  1008.000000  4158.000000   8521.000000   \n",
      "\n",
      "         word_diff  char_ratio  word_ratio  punct_real  punct_fake  ...  \\\n",
      "count    92.000000   92.000000   92.000000   92.000000   92.000000  ...   \n",
      "mean    -28.250000    1.573956    1.414684   37.771739   42.880435  ...   \n",
      "std     522.505284    1.740542    1.309458   42.134297   74.898296  ...   \n",
      "min   -3902.000000    0.041372    0.047619    1.000000    0.000000  ...   \n",
      "25%     -89.750000    0.656557    0.654771   16.000000   15.750000  ...   \n",
      "50%      10.000000    1.057776    1.034802   24.500000   22.500000  ...   \n",
      "75%     109.500000    1.657370    1.631880   37.250000   35.000000  ...   \n",
      "max     826.000000    9.184438    7.090909  178.000000  633.000000  ...   \n",
      "\n",
      "       real_large_nums  fake_large_nums  real_science_count  \\\n",
      "count        92.000000        92.000000           92.000000   \n",
      "mean          2.423913         2.554348            3.043478   \n",
      "std           2.794161         4.684236            1.932447   \n",
      "min           0.000000         0.000000            0.000000   \n",
      "25%           0.000000         0.000000            2.000000   \n",
      "50%           1.000000         1.000000            3.000000   \n",
      "75%           4.000000         3.000000            4.000000   \n",
      "max          13.000000        40.000000            8.000000   \n",
      "\n",
      "       fake_science_count  real_abbrev_count  fake_abbrev_count  \\\n",
      "count           92.000000          92.000000          92.000000   \n",
      "mean             2.989130           0.826087           0.934783   \n",
      "std              1.872265           0.921164           1.014232   \n",
      "min              0.000000           0.000000           0.000000   \n",
      "25%              1.000000           0.000000           0.000000   \n",
      "50%              3.000000           1.000000           1.000000   \n",
      "75%              4.000000           1.000000           1.000000   \n",
      "max              8.000000           4.000000           5.000000   \n",
      "\n",
      "       real_repetition_score  fake_repetition_score  real_unique_ratio  \\\n",
      "count              92.000000              92.000000          92.000000   \n",
      "mean              107.434783             103.315217           0.720893   \n",
      "std                65.980734              60.762360           0.105201   \n",
      "min                 4.000000              12.000000           0.518699   \n",
      "25%                61.000000              62.750000           0.658351   \n",
      "50%                91.000000              84.500000           0.700467   \n",
      "75%               132.000000             129.500000           0.754920   \n",
      "max               387.000000             314.000000           0.990556   \n",
      "\n",
      "       fake_unique_ratio  \n",
      "count          92.000000  \n",
      "mean            0.715895  \n",
      "std             0.129935  \n",
      "min             0.181818  \n",
      "25%             0.650331  \n",
      "50%             0.706709  \n",
      "75%             0.763095  \n",
      "max             0.990691  \n",
      "\n",
      "[8 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "features_df = extract_basic_features(clean_df)\n",
    "labels = (clean_df['real_file_label'] - 1).values\n",
    "print(features_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e6e0991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_real:\n",
      "  Mean: 2321.7283\n",
      "  Std:  2226.2692\n",
      "  Min:  69.0000\n",
      "  Max:  9561.0000\n",
      "\n",
      "char_fake:\n",
      "  Mean: 2622.3913\n",
      "  Std:  4519.0782\n",
      "  Min:  285.0000\n",
      "  Max:  40316.0000\n",
      "\n",
      "word_real:\n",
      "  Mean: 312.6087\n",
      "  Std:  229.4547\n",
      "  Min:  9.0000\n",
      "  Max:  1008.0000\n",
      "\n",
      "word_fake:\n",
      "  Mean: 340.8587\n",
      "  Std:  460.6857\n",
      "  Min:  32.0000\n",
      "  Max:  4158.0000\n",
      "\n",
      "char_diff:\n",
      "  Mean: -300.6630\n",
      "  Std:  5162.3925\n",
      "  Min:  -38648.0000\n",
      "  Max:  8521.0000\n",
      "  Real > Fake: 55/92 (59.8%)\n",
      "  Real < Fake: 37/92 (40.2%)\n",
      "  Real = Fake: 0/92 (0.0%)\n",
      "\n",
      "word_diff:\n",
      "  Mean: -28.2500\n",
      "  Std:  522.5053\n",
      "  Min:  -3902.0000\n",
      "  Max:  826.0000\n",
      "  Real > Fake: 51/92 (55.4%)\n",
      "  Real < Fake: 40/92 (43.5%)\n",
      "  Real = Fake: 1/92 (1.1%)\n",
      "\n",
      "char_ratio:\n",
      "  Mean: 1.5740\n",
      "  Std:  1.7405\n",
      "  Min:  0.0414\n",
      "  Max:  9.1844\n",
      "\n",
      "word_ratio:\n",
      "  Mean: 1.4147\n",
      "  Std:  1.3095\n",
      "  Min:  0.0476\n",
      "  Max:  7.0909\n",
      "\n",
      "punct_real:\n",
      "  Mean: 37.7717\n",
      "  Std:  42.1343\n",
      "  Min:  1.0000\n",
      "  Max:  178.0000\n",
      "\n",
      "punct_fake:\n",
      "  Mean: 42.8804\n",
      "  Std:  74.8983\n",
      "  Min:  0.0000\n",
      "  Max:  633.0000\n",
      "\n",
      "punct_diff:\n",
      "  Mean: -5.1087\n",
      "  Std:  87.6004\n",
      "  Min:  -611.0000\n",
      "  Max:  156.0000\n",
      "  Real > Fake: 44/92 (47.8%)\n",
      "  Real < Fake: 43/92 (46.7%)\n",
      "  Real = Fake: 5/92 (5.4%)\n",
      "\n",
      "real_punct_types:\n",
      "  Mean: 4.8261\n",
      "  Std:  1.7264\n",
      "  Min:  1.0000\n",
      "  Max:  8.0000\n",
      "\n",
      "fake_punct_types:\n",
      "  Mean: 4.7500\n",
      "  Std:  1.7705\n",
      "  Min:  0.0000\n",
      "  Max:  8.0000\n",
      "\n",
      "punct_density_real:\n",
      "  Mean: 0.1061\n",
      "  Std:  0.0356\n",
      "  Min:  0.0317\n",
      "  Max:  0.1929\n",
      "\n",
      "punct_density_fake:\n",
      "  Mean: 0.1035\n",
      "  Std:  0.0358\n",
      "  Min:  0.0000\n",
      "  Max:  0.1847\n",
      "\n",
      "punct_density_diff:\n",
      "  Mean: 0.0027\n",
      "  Std:  0.0386\n",
      "  Min:  -0.1004\n",
      "  Max:  0.1150\n",
      "  Real > Fake: 47/92 (51.1%)\n",
      "  Real < Fake: 44/92 (47.8%)\n",
      "  Real = Fake: 1/92 (1.1%)\n",
      "\n",
      "real_sent:\n",
      "  Mean: 17.2391\n",
      "  Std:  16.5711\n",
      "  Min:  1.0000\n",
      "  Max:  76.0000\n",
      "\n",
      "fake_sent:\n",
      "  Mean: 20.1413\n",
      "  Std:  38.1027\n",
      "  Min:  1.0000\n",
      "  Max:  348.0000\n",
      "\n",
      "sent_diff:\n",
      "  Mean: -2.9022\n",
      "  Std:  41.9385\n",
      "  Min:  -334.0000\n",
      "  Max:  67.0000\n",
      "  Real > Fake: 44/92 (47.8%)\n",
      "  Real < Fake: 39/92 (42.4%)\n",
      "  Real = Fake: 9/92 (9.8%)\n",
      "\n",
      "sent_ratio:\n",
      "  Mean: 1.4184\n",
      "  Std:  1.6160\n",
      "  Min:  0.0401\n",
      "  Max:  7.7500\n",
      "\n",
      "word_var_real:\n",
      "  Mean: 12.3761\n",
      "  Std:  8.8904\n",
      "  Min:  6.5622\n",
      "  Max:  44.2955\n",
      "\n",
      "word_var_fake:\n",
      "  Mean: 12.4253\n",
      "  Std:  8.9121\n",
      "  Min:  5.7732\n",
      "  Max:  40.4083\n",
      "\n",
      "word_var_diff:\n",
      "  Mean: -0.0492\n",
      "  Std:  13.1348\n",
      "  Min:  -31.6988\n",
      "  Max:  36.0472\n",
      "  Real > Fake: 48/92 (52.2%)\n",
      "  Real < Fake: 44/92 (47.8%)\n",
      "  Real = Fake: 0/92 (0.0%)\n",
      "\n",
      "real_proper:\n",
      "  Mean: 37.5326\n",
      "  Std:  38.2885\n",
      "  Min:  4.0000\n",
      "  Max:  181.0000\n",
      "\n",
      "fake_proper:\n",
      "  Mean: 44.6413\n",
      "  Std:  75.9561\n",
      "  Min:  3.0000\n",
      "  Max:  680.0000\n",
      "\n",
      "proper_diff:\n",
      "  Mean: -7.1087\n",
      "  Std:  84.6194\n",
      "  Min:  -667.0000\n",
      "  Max:  123.0000\n",
      "  Real > Fake: 42/92 (45.7%)\n",
      "  Real < Fake: 44/92 (47.8%)\n",
      "  Real = Fake: 6/92 (6.5%)\n",
      "\n",
      "proper_density_real:\n",
      "  Mean: 0.1198\n",
      "  Std:  0.0803\n",
      "  Min:  0.0288\n",
      "  Max:  0.6000\n",
      "\n",
      "proper_density_fake:\n",
      "  Mean: 0.1219\n",
      "  Std:  0.0595\n",
      "  Min:  0.0187\n",
      "  Max:  0.3606\n",
      "\n",
      "real_numbers:\n",
      "  Mean: 7.8804\n",
      "  Std:  8.6582\n",
      "  Min:  0.0000\n",
      "  Max:  45.0000\n",
      "\n",
      "fake_numbers:\n",
      "  Mean: 7.6630\n",
      "  Std:  9.0800\n",
      "  Min:  0.0000\n",
      "  Max:  67.0000\n",
      "\n",
      "numbers_diff:\n",
      "  Mean: 0.2174\n",
      "  Std:  8.5521\n",
      "  Min:  -51.0000\n",
      "  Max:  38.0000\n",
      "  Real > Fake: 27/92 (29.3%)\n",
      "  Real < Fake: 31/92 (33.7%)\n",
      "  Real = Fake: 34/92 (37.0%)\n",
      "\n",
      "real_precise_nums:\n",
      "  Mean: 1.6196\n",
      "  Std:  2.4844\n",
      "  Min:  0.0000\n",
      "  Max:  11.0000\n",
      "\n",
      "fake_precise_nums:\n",
      "  Mean: 1.4130\n",
      "  Std:  2.0063\n",
      "  Min:  0.0000\n",
      "  Max:  8.0000\n",
      "\n",
      "real_large_nums:\n",
      "  Mean: 2.4239\n",
      "  Std:  2.7942\n",
      "  Min:  0.0000\n",
      "  Max:  13.0000\n",
      "\n",
      "fake_large_nums:\n",
      "  Mean: 2.5543\n",
      "  Std:  4.6842\n",
      "  Min:  0.0000\n",
      "  Max:  40.0000\n",
      "\n",
      "real_science_count:\n",
      "  Mean: 3.0435\n",
      "  Std:  1.9324\n",
      "  Min:  0.0000\n",
      "  Max:  8.0000\n",
      "\n",
      "fake_science_count:\n",
      "  Mean: 2.9891\n",
      "  Std:  1.8723\n",
      "  Min:  0.0000\n",
      "  Max:  8.0000\n",
      "\n",
      "real_abbrev_count:\n",
      "  Mean: 0.8261\n",
      "  Std:  0.9212\n",
      "  Min:  0.0000\n",
      "  Max:  4.0000\n",
      "\n",
      "fake_abbrev_count:\n",
      "  Mean: 0.9348\n",
      "  Std:  1.0142\n",
      "  Min:  0.0000\n",
      "  Max:  5.0000\n",
      "\n",
      "real_repetition_score:\n",
      "  Mean: 107.4348\n",
      "  Std:  65.9807\n",
      "  Min:  4.0000\n",
      "  Max:  387.0000\n",
      "\n",
      "fake_repetition_score:\n",
      "  Mean: 103.3152\n",
      "  Std:  60.7624\n",
      "  Min:  12.0000\n",
      "  Max:  314.0000\n",
      "\n",
      "real_unique_ratio:\n",
      "  Mean: 0.7209\n",
      "  Std:  0.1052\n",
      "  Min:  0.5187\n",
      "  Max:  0.9906\n",
      "\n",
      "fake_unique_ratio:\n",
      "  Mean: 0.7159\n",
      "  Std:  0.1299\n",
      "  Min:  0.1818\n",
      "  Max:  0.9907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_feature_distributions(features_df):\n",
    "    for feature in features_df.columns:\n",
    "        values = features_df[feature]\n",
    "        \n",
    "        print(f\"{feature}:\")\n",
    "        print(f\"  Mean: {values.mean():.4f}\")\n",
    "        print(f\"  Std:  {values.std():.4f}\")\n",
    "        print(f\"  Min:  {values.min():.4f}\")\n",
    "        print(f\"  Max:  {values.max():.4f}\")\n",
    "        \n",
    "        # For difference features, show how often real > fake\n",
    "        if 'diff' in feature:\n",
    "            positive_count = (values > 0).sum()\n",
    "            negative_count = (values < 0).sum()\n",
    "            zero_count = (values == 0).sum()\n",
    "            total = len(values)\n",
    "            \n",
    "            print(f\"  Real > Fake: {positive_count}/{total} ({100*positive_count/total:.1f}%)\")\n",
    "            print(f\"  Real < Fake: {negative_count}/{total} ({100*negative_count/total:.1f}%)\")\n",
    "            print(f\"  Real = Fake: {zero_count}/{total} ({100*zero_count/total:.1f}%)\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "analyze_feature_distributions(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "353f99ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_real vs char_fake:\n",
      "  Real mean: 2321.7283\n",
      "  Fake mean: 2622.3913\n",
      "  Difference: -300.6630\n",
      "\n",
      "word_real vs word_fake:\n",
      "  Real mean: 312.6087\n",
      "  Fake mean: 340.8587\n",
      "  Difference: -28.2500\n",
      "\n",
      "punct_real vs punct_fake:\n",
      "  Real mean: 37.7717\n",
      "  Fake mean: 42.8804\n",
      "  Difference: -5.1087\n",
      "\n",
      "punct_density_real vs punct_density_fake:\n",
      "  Real mean: 0.1061\n",
      "  Fake mean: 0.1035\n",
      "  Difference: 0.0027\n",
      "\n",
      "real_sent vs fake_sent:\n",
      "  Real mean: 17.2391\n",
      "  Fake mean: 20.1413\n",
      "  Difference: -2.9022\n",
      "\n",
      "word_var_real vs word_var_fake:\n",
      "  Real mean: 12.3761\n",
      "  Fake mean: 12.4253\n",
      "  Difference: -0.0492\n",
      "\n",
      "real_proper vs fake_proper:\n",
      "  Real mean: 37.5326\n",
      "  Fake mean: 44.6413\n",
      "  Difference: -7.1087\n",
      "\n",
      "proper_density_real vs proper_density_fake:\n",
      "  Real mean: 0.1198\n",
      "  Fake mean: 0.1219\n",
      "  Difference: -0.0020\n",
      "\n",
      "real_punct_types vs fake_punct_types:\n",
      "  Real mean: 4.8261\n",
      "  Fake mean: 4.7500\n",
      "  Difference: 0.0761\n",
      "\n",
      "real_numbers vs fake_numbers:\n",
      "  Real mean: 7.8804\n",
      "  Fake mean: 7.6630\n",
      "  Difference: 0.2174\n",
      "\n",
      "real_precise_nums vs fake_precise_nums:\n",
      "  Real mean: 1.6196\n",
      "  Fake mean: 1.4130\n",
      "  Difference: 0.2065\n",
      "\n",
      "real_large_nums vs fake_large_nums:\n",
      "  Real mean: 2.4239\n",
      "  Fake mean: 2.5543\n",
      "  Difference: -0.1304\n",
      "\n",
      "real_science_count vs fake_science_count:\n",
      "  Real mean: 3.0435\n",
      "  Fake mean: 2.9891\n",
      "  Difference: 0.0543\n",
      "\n",
      "real_abbrev_count vs fake_abbrev_count:\n",
      "  Real mean: 0.8261\n",
      "  Fake mean: 0.9348\n",
      "  Difference: -0.1087\n",
      "\n",
      "real_repetition_score vs fake_repetition_score:\n",
      "  Real mean: 107.4348\n",
      "  Fake mean: 103.3152\n",
      "  Difference: 4.1196\n",
      "\n",
      "real_unique_ratio vs fake_unique_ratio:\n",
      "  Real mean: 0.7209\n",
      "  Fake mean: 0.7159\n",
      "  Difference: 0.0050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_real_vs_fake_features(features_df):    \n",
    "    # Compare pairs of real/fake features\n",
    "    feature_pairs = [\n",
    "        ('char_real', 'char_fake'),\n",
    "        ('word_real', 'word_fake'),\n",
    "        ('punct_real', 'punct_fake'),\n",
    "        ('punct_density_real', 'punct_density_fake'),\n",
    "        ('real_sent', 'fake_sent'),\n",
    "        ('word_var_real', 'word_var_fake'),\n",
    "        ('real_proper', 'fake_proper'),\n",
    "        ('proper_density_real', 'proper_density_fake'),\n",
    "        ('real_punct_types', 'fake_punct_types'),\n",
    "        ('real_numbers', 'fake_numbers'),\n",
    "        ('real_precise_nums', 'fake_precise_nums'),\n",
    "        ('real_large_nums','fake_large_nums'),\n",
    "        ('real_science_count', 'fake_science_count'),\n",
    "        ('real_abbrev_count', 'fake_abbrev_count'),\n",
    "        ('real_repetition_score', 'fake_repetition_score'),\n",
    "        ('real_unique_ratio', 'fake_unique_ratio')\n",
    "    ]\n",
    "    \n",
    "    for real_feature, fake_feature in feature_pairs:\n",
    "        if real_feature in features_df.columns and fake_feature in features_df.columns:\n",
    "            real_values = features_df[real_feature]\n",
    "            fake_values = features_df[fake_feature]\n",
    "            \n",
    "            print(f\"{real_feature} vs {fake_feature}:\")\n",
    "            print(f\"  Real mean: {real_values.mean():.4f}\")\n",
    "            print(f\"  Fake mean: {fake_values.mean():.4f}\")\n",
    "            print(f\"  Difference: {real_values.mean() - fake_values.mean():.4f}\")\n",
    "            print()\n",
    "\n",
    "compare_real_vs_fake_features(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab9572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
