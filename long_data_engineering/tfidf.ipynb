{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering\n",
    "\n",
    "This notebook will investigate the outcomes of thorough feature engineering above to improve baseline performance (64%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>text</th>\n",
       "      <th>is_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder                                               text  is_real\n",
       "0       0  The VIRSA (Visible Infrared Survey Telescope A...        1\n",
       "1       0  The China relay network has released a signifi...        0\n",
       "2       1  China\\nThe goal of this project involves achie...        0\n",
       "3       1  The project aims to achieve an accuracy level ...        1\n",
       "4       2  Scientists can learn about how galaxies form a...        1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = \"../data/train_long_df.csv\"\n",
    "train_df = pd.read_csv(training_data, dtype={'folder': int, 'text': str, 'is_real': int})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NA Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples before data cleaning: 190\n",
      "Number of samples before data cleaning: 188\n"
     ]
    }
   ],
   "source": [
    "clean_df = train_df.copy()\n",
    "print(f\"Number of samples before data cleaning: {len(clean_df)}\")\n",
    "\n",
    "# Removing NA rows altogether \n",
    "clean_df.dropna(subset=[\"text\"], inplace=True)\n",
    "print(f\"Number of samples before data cleaning: {len(clean_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_char</th>\n",
       "      <th>num_words</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>num_punct_types</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>word_var</th>\n",
       "      <th>proper_noun_count</th>\n",
       "      <th>proper_noun_density</th>\n",
       "      <th>num_numbers</th>\n",
       "      <th>num_precise_num</th>\n",
       "      <th>num_large_num</th>\n",
       "      <th>num_science_terms</th>\n",
       "      <th>num_abbrev</th>\n",
       "      <th>repetition_score</th>\n",
       "      <th>unique_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2196</td>\n",
       "      <td>304</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>8.116246</td>\n",
       "      <td>38</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>296</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>26.818182</td>\n",
       "      <td>8.045642</td>\n",
       "      <td>20</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0.794613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3124</td>\n",
       "      <td>454</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>8.279323</td>\n",
       "      <td>17</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>0.696703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>936</td>\n",
       "      <td>137</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>9.229687</td>\n",
       "      <td>6</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1139</td>\n",
       "      <td>159</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.398837</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0.818750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_char  num_words  punctuation_count  num_punct_types  num_sentences  \\\n",
       "0      2196        304                 16                4              9   \n",
       "1      2018        296                 18                6             10   \n",
       "2      3124        454                 17                7              9   \n",
       "3       936        137                 11                5              6   \n",
       "4      1139        159                  9                5              4   \n",
       "\n",
       "   avg_sent_length  word_var  proper_noun_count  proper_noun_density  \\\n",
       "0        29.800000  8.116246                 38             0.974359   \n",
       "1        26.818182  8.045642                 20             0.952381   \n",
       "2        45.500000  8.279323                 17             0.944444   \n",
       "3        19.428571  9.229687                  6             0.857143   \n",
       "4        31.800000  7.398837                  3             0.750000   \n",
       "\n",
       "   num_numbers  num_precise_num  num_large_num  num_science_terms  num_abbrev  \\\n",
       "0            0                0              0                  6           5   \n",
       "1            0                0              0                  5           0   \n",
       "2            1                0              0                  2           0   \n",
       "3            6                1              3                  3           0   \n",
       "4            0                0              0                  4           0   \n",
       "\n",
       "   repetition_score  unique_ratio  \n",
       "0               102      0.800000  \n",
       "1               103      0.794613  \n",
       "2               233      0.696703  \n",
       "3                36      0.847826  \n",
       "4                47      0.818750  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for idx, row in clean_df.iterrows():\n",
    "    text = row['text']\n",
    "    \n",
    "    # Basic length features\n",
    "    num_chars = len(text)\n",
    "    num_words = len(text.split())\n",
    "    \n",
    "    # Basic punctuation features\n",
    "    punctuation_count = len(re.findall(r'[.!?,:;]', text))\n",
    "    num_punct_types = len(set(re.findall(r'[.!?,:;()]', text)))\n",
    "    \n",
    "    # Basic sentence features\n",
    "    num_sentences = len([s for s in re.split(r'[.!?]+', text) if s.strip()])\n",
    "    avg_sent_length = np.mean([len(s.split()) for s in re.split(r'[.!?]+', text)]) if num_sentences else 0\n",
    "    \n",
    "    # Basic variance features\n",
    "    word_lengths = [len(w) for w in text.split()] if num_words > 0 else [0]\n",
    "    word_var = np.var(word_lengths) if len(word_lengths) > 1 else 0\n",
    "    \n",
    "    # Count proper nouns\n",
    "    proper_noun_count = len([w for i, w in enumerate(text.split()) \n",
    "                        if w and w[0].isupper() and i > 0])\n",
    "    \n",
    "    # Numbers\n",
    "    num_numbers = len(re.findall(r'\\d+', text))\n",
    "    num_precise_num = len([n for n in re.findall(r'\\d+\\.?\\d*', text) if '.' in n])\n",
    "    num_large_num = len([n for n in re.findall(r'\\d+', text) if len(n) >= 3])\n",
    "\n",
    "    # Science terms\n",
    "    science_terms = ['telescope', 'survey', 'observation', 'stellar', 'galaxy', 'star', \n",
    "            'astronomical', 'magnitude', 'photometric', 'spectroscopic', \n",
    "            'wavelength', 'redshift', 'luminosity', 'parsec', 'light-year']\n",
    "\n",
    "    num_science_terms = sum(1 for term in science_terms if term.lower() in text.lower())\n",
    "\n",
    "    # Abbreviations\n",
    "    abbrevs = ['ESO', 'NASA', 'VLT', 'HST', 'ALMA', 'VISTA', 'VIRSA', 'VMC', 'VVV']\n",
    "    num_abbrev = sum(1 for abbrev in abbrevs if abbrev in text)\n",
    "\n",
    "    # Repetition patterns\n",
    "    real_word_freq = Counter(text.lower().split())\n",
    "    repetition_score = sum(count for count in real_word_freq.values() if count > 1)\n",
    "    unique_ratio = len(set(text.lower().split())) / (len(text.split()) + 1)\n",
    "    \n",
    "    feature_row = {\n",
    "        # Length differences\n",
    "        'num_char': num_chars,\n",
    "        'num_words': num_words,\n",
    "        \n",
    "        # Punctuation differences  \n",
    "        'punctuation_count': punctuation_count,\n",
    "        'num_punct_types': num_punct_types,\n",
    "        \n",
    "        # Sentence differences\n",
    "        'num_sentences': num_sentences,\n",
    "        'avg_sent_length': avg_sent_length,\n",
    "        \n",
    "        # Variance differences\n",
    "        'word_var': word_var,\n",
    "        \n",
    "        # Content differences\n",
    "        'proper_noun_count': proper_noun_count,\n",
    "        'proper_noun_density': proper_noun_count / (proper_noun_count + 1),\n",
    "\n",
    "        # Numbers\n",
    "        'num_numbers': num_numbers,\n",
    "        'num_precise_num': num_precise_num,\n",
    "        'num_large_num': num_large_num,\n",
    "\n",
    "        # Science terms\n",
    "        'num_science_terms': num_science_terms,\n",
    "\n",
    "        # Abbreviations\n",
    "        'num_abbrev': num_abbrev,\n",
    "\n",
    "        # Repetition patterns\n",
    "        'repetition_score': repetition_score,\n",
    "        'unique_ratio': unique_ratio,\n",
    "    }\n",
    "    \n",
    "    features.append(feature_row)\n",
    "\n",
    "feature_df = pd.DataFrame(features)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "  Accuracy: 0.6579\n",
      "  Cross-Validation Score (Mean): 0.7533\n",
      "\n",
      "Model: Random Forest\n",
      "  Accuracy: 0.6579\n",
      "  Cross-Validation Score (Mean): 0.7000\n",
      "\n",
      "Model: Gradient Boosting\n",
      "  Accuracy: 0.6316\n",
      "  Cross-Validation Score (Mean): 0.6200\n",
      "\n",
      "Model: Ensemble (Majority Vote)\n",
      "  Accuracy: 0.6053\n",
      "  Cross-Validation Score (Mean): 0.7133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size=0.2\n",
    "random_state=42\n",
    "\n",
    "X = feature_df\n",
    "# Our labels for the real text\n",
    "y = (clean_df['is_real']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "lr = LogisticRegression(random_state=random_state, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "models['Logistic Regression'] = lr\n",
    "results['Logistic Regression'] = {\n",
    "    'accuracy': accuracy_score(y_test, lr_pred),\n",
    "    'cv_score': cross_val_score(lr, X_train_scaled, y_train, cv=5).mean()\n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "models['Random Forest'] = rf\n",
    "results['Random Forest'] = {\n",
    "    'accuracy': accuracy_score(y_test, rf_pred),\n",
    "    'cv_score': cross_val_score(rf, X_train_scaled, y_train, cv=5).mean()\n",
    "}\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=random_state)\n",
    "gb.fit(X_train_scaled, y_train)\n",
    "gb_pred = gb.predict(X_test_scaled)\n",
    "models['Gradient Boosting'] = gb\n",
    "results['Gradient Boosting'] = {\n",
    "    'accuracy': accuracy_score(y_test, gb_pred),\n",
    "    'cv_score': cross_val_score(gb, X_train_scaled, y_train, cv=5).mean()\n",
    "}\n",
    "\n",
    "estimators = [\n",
    "    ('lr', models['Logistic Regression']),\n",
    "    ('rf', models['Random Forest']),\n",
    "    ('gb', models['Gradient Boosting'])\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=estimators, voting='hard')\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "ensemble_pred = ensemble_model.predict(X_test_scaled)\n",
    "models['Ensemble (Majority Vote)'] = ensemble_model\n",
    "results['Ensemble (Majority Vote)'] = {\n",
    "    'accuracy': accuracy_score(y_test, ensemble_pred),\n",
    "    'cv_score': cross_val_score(ensemble_model, X_train_scaled, y_train, cv=5).mean()\n",
    "}\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Cross-Validation Score (Mean): {metrics['cv_score']:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Music\" Music music music Music music Music mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Since its launch on Paranal observatory's Very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>underground exploration on SN's birth has prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SN 1987A provides valuable insights as newer o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>This research aimed to understand how star sha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder                                               text\n",
       "0       0  \"Music\" Music music music Music music Music mu...\n",
       "1       0  Since its launch on Paranal observatory's Very...\n",
       "2       1  underground exploration on SN's birth has prov...\n",
       "3       1  SN 1987A provides valuable insights as newer o...\n",
       "4       2  This research aimed to understand how star sha..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = \"../data/test_long_df.csv\"\n",
    "test_df = pd.read_csv(test_data, dtype={'folder': int, 'text': str, 'is_real': int})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_char</th>\n",
       "      <th>num_words</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>num_punct_types</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>word_var</th>\n",
       "      <th>proper_noun_count</th>\n",
       "      <th>proper_noun_density</th>\n",
       "      <th>num_numbers</th>\n",
       "      <th>num_precise_num</th>\n",
       "      <th>num_large_num</th>\n",
       "      <th>num_science_terms</th>\n",
       "      <th>num_abbrev</th>\n",
       "      <th>repetition_score</th>\n",
       "      <th>unique_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>262</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>28.888889</td>\n",
       "      <td>7.890289</td>\n",
       "      <td>18</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0.726236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1249</td>\n",
       "      <td>173</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>33.800000</td>\n",
       "      <td>10.602359</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0.775862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1168</td>\n",
       "      <td>165</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>7.823104</td>\n",
       "      <td>17</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.855422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1516</td>\n",
       "      <td>216</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>30.285714</td>\n",
       "      <td>8.031872</td>\n",
       "      <td>20</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0.783410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>752</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>6.789461</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.769912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_char  num_words  punctuation_count  num_punct_types  num_sentences  \\\n",
       "0      1710        262                  9                5              8   \n",
       "1      1249        173                 10                5              4   \n",
       "2      1168        165                 10                6              5   \n",
       "3      1516        216                 11                5              6   \n",
       "4       752        112                  3                3              3   \n",
       "\n",
       "   avg_sent_length   word_var  proper_noun_count  proper_noun_density  \\\n",
       "0        28.888889   7.890289                 18             0.947368   \n",
       "1        33.800000  10.602359                  9             0.900000   \n",
       "2        27.500000   7.823104                 17             0.944444   \n",
       "3        30.285714   8.031872                 20             0.952381   \n",
       "4        27.750000   6.789461                  2             0.666667   \n",
       "\n",
       "   num_numbers  num_precise_num  num_large_num  num_science_terms  num_abbrev  \\\n",
       "0            0                0              0                  2           0   \n",
       "1            0                0              0                  3           1   \n",
       "2            0                0              0                  2           1   \n",
       "3            5                0              2                  2           1   \n",
       "4            0                0              0                  1           0   \n",
       "\n",
       "   repetition_score  unique_ratio  \n",
       "0               116      0.726236  \n",
       "1                67      0.775862  \n",
       "2                43      0.855422  \n",
       "3                78      0.783410  \n",
       "4                46      0.769912  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NaN values\n",
    "test_df['text'] = test_df['text'].fillna('').astype(str)\n",
    "\n",
    "test_features = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    text = row['text']\n",
    "    \n",
    "    # Basic length features\n",
    "    num_chars = len(text)\n",
    "    num_words = len(text.split())\n",
    "    \n",
    "    # Basic punctuation features\n",
    "    punctuation_count = len(re.findall(r'[.!?,:;]', text))\n",
    "    num_punct_types = len(set(re.findall(r'[.!?,:;()]', text)))\n",
    "    \n",
    "    # Basic sentence features\n",
    "    num_sentences = len([s for s in re.split(r'[.!?]+', text) if s.strip()])\n",
    "    avg_sent_length = np.mean([len(s.split()) for s in re.split(r'[.!?]+', text)]) if num_sentences else 0\n",
    "    \n",
    "    # Basic variance features\n",
    "    word_lengths = [len(w) for w in text.split()] if num_words > 0 else [0]\n",
    "    word_var = np.var(word_lengths) if len(word_lengths) > 1 else 0\n",
    "    \n",
    "    # Count proper nouns\n",
    "    proper_noun_count = len([w for i, w in enumerate(text.split()) \n",
    "                        if w and w[0].isupper() and i > 0])\n",
    "    \n",
    "    # Numbers\n",
    "    num_numbers = len(re.findall(r'\\d+', text))\n",
    "    num_precise_num = len([n for n in re.findall(r'\\d+\\.?\\d*', text) if '.' in n])\n",
    "    num_large_num = len([n for n in re.findall(r'\\d+', text) if len(n) >= 3])\n",
    "\n",
    "    # Science terms\n",
    "    science_terms = ['telescope', 'survey', 'observation', 'stellar', 'galaxy', 'star', \n",
    "            'astronomical', 'magnitude', 'photometric', 'spectroscopic', \n",
    "            'wavelength', 'redshift', 'luminosity', 'parsec', 'light-year']\n",
    "\n",
    "    num_science_terms = sum(1 for term in science_terms if term.lower() in text.lower())\n",
    "\n",
    "    # Abbreviations\n",
    "    abbrevs = ['ESO', 'NASA', 'VLT', 'HST', 'ALMA', 'VISTA', 'VIRSA', 'VMC', 'VVV']\n",
    "    num_abbrev = sum(1 for abbrev in abbrevs if abbrev in text)\n",
    "\n",
    "    # Repetition patterns\n",
    "    real_word_freq = Counter(text.lower().split())\n",
    "    repetition_score = sum(count for count in real_word_freq.values() if count > 1)\n",
    "    unique_ratio = len(set(text.lower().split())) / (len(text.split()) + 1)\n",
    "    \n",
    "    feature_row = {\n",
    "        # Length differences\n",
    "        'num_char': num_chars,\n",
    "        'num_words': num_words,\n",
    "        \n",
    "        # Punctuation differences  \n",
    "        'punctuation_count': punctuation_count,\n",
    "        'num_punct_types': num_punct_types,\n",
    "        \n",
    "        # Sentence differences\n",
    "        'num_sentences': num_sentences,\n",
    "        'avg_sent_length': avg_sent_length,\n",
    "        \n",
    "        # Variance differences\n",
    "        'word_var': word_var,\n",
    "        \n",
    "        # Content differences\n",
    "        'proper_noun_count': proper_noun_count,\n",
    "        'proper_noun_density': proper_noun_count / (proper_noun_count + 1),\n",
    "\n",
    "        # Numbers\n",
    "        'num_numbers': num_numbers,\n",
    "        'num_precise_num': num_precise_num,\n",
    "        'num_large_num': num_large_num,\n",
    "\n",
    "        # Science terms\n",
    "        'num_science_terms': num_science_terms,\n",
    "\n",
    "        # Abbreviations\n",
    "        'num_abbrev': num_abbrev,\n",
    "\n",
    "        # Repetition patterns\n",
    "        'repetition_score': repetition_score,\n",
    "        'unique_ratio': unique_ratio,\n",
    "    }\n",
    "    \n",
    "    test_features.append(feature_row)\n",
    "\n",
    "test_features_df = pd.DataFrame(test_features)\n",
    "test_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff count: 558\n"
     ]
    }
   ],
   "source": [
    "test_features_df = test_features_df[feature_df.columns]\n",
    "\n",
    "# Scale features using fitted scaler\n",
    "test_features_scaled = scaler.transform(test_features_df)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = ensemble_model.predict(test_features_scaled)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df = predictions_df.reset_index().rename(columns={'index': 'id', 0: 'real_text_id'})\n",
    "\n",
    "# Place text pair predictions on the same row\n",
    "real_text_ids = predictions_df['real_text_id']\n",
    "new_list_array = real_text_ids.to_numpy().reshape(-1, 2)\n",
    "paired_df = pd.DataFrame(new_list_array)\n",
    "\n",
    "# \n",
    "diff_count = 0\n",
    "reduced_values = []\n",
    "for idx, row in paired_df.iterrows():\n",
    "    col0_val = row[0]\n",
    "    col1_val = row[1]\n",
    "    transformed_value = None\n",
    "\n",
    "    if col0_val == 0 and col1_val == 1:\n",
    "        transformed_value = 2\n",
    "    elif col0_val == 1 and col1_val == 0:\n",
    "        transformed_value = 1\n",
    "    elif (col0_val == 1 and col1_val == 1) or \\\n",
    "         (col0_val == 0 and col1_val == 0):\n",
    "        diff_count += 1\n",
    "        transformed_value = random.choice([1, 2])\n",
    "\n",
    "    reduced_values.append(transformed_value)\n",
    "\n",
    "final_predictions_df = pd.DataFrame(reduced_values).rename(columns={'index': 'id', 0: 'real_text_id'})\n",
    "timestamp_str = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "final_predictions_df.to_csv(f\"../predictions/predictions_em_{timestamp_str}.csv\")\n",
    "print(f\"diff count: {diff_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to flip the prediction label -> this is definately wrong\n",
    "file = pd.read_csv(\"../predictions/predictions_em_2025-07-10_14:12:24.csv\")\n",
    "file['real_text_id'] = file['real_text_id'].map({1: 2, 2: 1})\n",
    "timestamp_str = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "file.to_csv(f\"../predictions/predictions_em_{timestamp_str}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
