{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier for Baseline Performance\n",
    "\n",
    "Efforts in another notebook reveal Random Forest has the best performance of the simple ML models. This notebook will establish the data extraction, training loop and test prediction scripts necessary to implement a random forest for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Training Data\n",
    "\n",
    "The following code will ingest data from a predefined merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "      <th>real_file_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             file_1  \\\n",
       "0      0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1      1  China\\nThe goal of this project involves achie...   \n",
       "2      2  Scientists can learn about how galaxies form a...   \n",
       "3      3  China\\nThe study suggests that multiple star s...   \n",
       "4      4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              file_2  real_file_label  \n",
       "0  The China relay network has released a signifi...                2  \n",
       "1  The project aims to achieve an accuracy level ...                1  \n",
       "2  Dinosaur eggshells offer clues about what dino...                2  \n",
       "3  The importance for understanding how stars evo...                2  \n",
       "4  Analyzing how fast stars rotate within a galax...                1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = \"../data/train_df.csv\"\n",
    "train_df = pd.read_csv(training_data, dtype={'file_1': str, 'file_2': str, 'real_file_label': int})\n",
    "train_df.rename(columns={\"Unnamed: 0\": \"index\"}, inplace=True) # Mistake from origin df\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove NA Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples before data cleaning: 94\n",
      "Number of samples before data cleaning: 92\n"
     ]
    }
   ],
   "source": [
    "clean_df = train_df.copy()\n",
    "print(f\"Number of samples before data cleaning: {len(clean_df)}\")\n",
    "\n",
    "# Removing NA rows altogether \n",
    "clean_df.dropna(subset=[\"file_1\", \"file_2\"], inplace=True)\n",
    "print(f\"Number of samples before data cleaning: {len(clean_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Feature Extraction \n",
    "\n",
    "The following code snippit will extract basic text related features from each of the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_ratio</th>\n",
       "      <th>word_ratio</th>\n",
       "      <th>char_diff</th>\n",
       "      <th>word_diff</th>\n",
       "      <th>punct_diff</th>\n",
       "      <th>sent_diff</th>\n",
       "      <th>punct_density_diff</th>\n",
       "      <th>proper_density_diff</th>\n",
       "      <th>word_var_diff</th>\n",
       "      <th>word_var_ratio</th>\n",
       "      <th>numbers_diff</th>\n",
       "      <th>proper_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.918525</td>\n",
       "      <td>0.970492</td>\n",
       "      <td>-178</td>\n",
       "      <td>-8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>-0.057250</td>\n",
       "      <td>-0.070604</td>\n",
       "      <td>0.991301</td>\n",
       "      <td>0</td>\n",
       "      <td>-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.334045</td>\n",
       "      <td>3.289855</td>\n",
       "      <td>2188</td>\n",
       "      <td>317</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.042348</td>\n",
       "      <td>-0.006116</td>\n",
       "      <td>-0.950364</td>\n",
       "      <td>0.897032</td>\n",
       "      <td>-5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.702632</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>-338</td>\n",
       "      <td>-34</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.024504</td>\n",
       "      <td>0.028869</td>\n",
       "      <td>-0.531893</td>\n",
       "      <td>0.928111</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.052958</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>95</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.018781</td>\n",
       "      <td>-0.071797</td>\n",
       "      <td>0.663026</td>\n",
       "      <td>1.081888</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223624</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>-676</td>\n",
       "      <td>-89</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114977</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>-2.715467</td>\n",
       "      <td>0.710071</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_ratio  word_ratio  char_diff  word_diff  punct_diff  sent_diff  \\\n",
       "0    0.918525    0.970492       -178         -8           2          1   \n",
       "1    3.334045    3.289855       2188        317           6          3   \n",
       "2    0.702632    0.781250       -338        -34          -5         -1   \n",
       "3    1.052958    0.992424         95         -1          -5         -1   \n",
       "4    0.223624    0.274194       -676        -89          -1          0   \n",
       "\n",
       "   punct_density_diff  proper_density_diff  word_var_diff  word_var_ratio  \\\n",
       "0            0.008147            -0.057250      -0.070604        0.991301   \n",
       "1           -0.042348            -0.006116      -0.950364        0.897032   \n",
       "2           -0.024504             0.028869      -0.531893        0.928111   \n",
       "3           -0.018781            -0.071797       0.663026        1.081888   \n",
       "4            0.114977             0.090092      -2.715467        0.710071   \n",
       "\n",
       "   numbers_diff  proper_diff  \n",
       "0             0          -18  \n",
       "1            -5           11  \n",
       "2             1            3  \n",
       "3             0          -19  \n",
       "4            -1            1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating real_text and fake_text columns\n",
    "clean_df['real_text'] = clean_df.apply(\n",
    "    lambda row: row['file_1'] if row['real_file_label'] == 1 else row['file_2'], \n",
    "    axis=1\n",
    ")\n",
    "clean_df['fake_text'] = clean_df.apply(\n",
    "    lambda row: row['file_2'] if row['real_file_label'] == 1 else row['file_1'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Iterating through rows and generating features\n",
    "features = []\n",
    "for idx, row in clean_df.iterrows():\n",
    "    real_text = str(row['real_text'])\n",
    "    fake_text = str(row['fake_text'])\n",
    "    \n",
    "    # Basic length features\n",
    "    real_chars = len(real_text)\n",
    "    fake_chars = len(fake_text)\n",
    "    real_words = len(real_text.split())\n",
    "    fake_words = len(fake_text.split())\n",
    "    \n",
    "    # Basic punctuation features\n",
    "    real_punct = len(re.findall(r'[.!?,:;]', real_text))\n",
    "    fake_punct = len(re.findall(r'[.!?,:;]', fake_text))\n",
    "    \n",
    "    # Basic sentence features\n",
    "    real_sents = len([s for s in re.split(r'[.!?]+', real_text) if s.strip()])\n",
    "    fake_sents = len([s for s in re.split(r'[.!?]+', fake_text) if s.strip()])\n",
    "    \n",
    "    # Word variance\n",
    "    real_word_lengths = [len(w) for w in real_text.split()] if real_words > 0 else [0]\n",
    "    fake_word_lengths = [len(w) for w in fake_text.split()] if fake_words > 0 else [0]\n",
    "    real_word_var = np.var(real_word_lengths) if len(real_word_lengths) > 1 else 0\n",
    "    fake_word_var = np.var(fake_word_lengths) if len(fake_word_lengths) > 1 else 0\n",
    "    \n",
    "    # Proper nouns\n",
    "    real_proper = len([w for i, w in enumerate(real_text.split()) \n",
    "                        if w and w[0].isupper() and i > 0])\n",
    "    fake_proper = len([w for i, w in enumerate(fake_text.split()) \n",
    "                        if w and w[0].isupper() and i > 0])\n",
    "    \n",
    "    # Numbers\n",
    "    real_numbers = len(re.findall(r'\\d+', real_text))\n",
    "    fake_numbers = len(re.findall(r'\\d+', fake_text))\n",
    "    \n",
    "    # Select most promising features for baseline\n",
    "    feature_row = {\n",
    "        # Length ratios\n",
    "        'char_ratio': real_chars / (fake_chars + 1),\n",
    "        'word_ratio': real_words / (fake_words + 1),\n",
    "        \n",
    "        # Difference features\n",
    "        'char_diff': real_chars - fake_chars,\n",
    "        'word_diff': real_words - fake_words,\n",
    "        'punct_diff': real_punct - fake_punct,\n",
    "        'sent_diff': real_sents - fake_sents,\n",
    "        \n",
    "        # Density features\n",
    "        'punct_density_diff': (real_punct / (real_words + 1)) - (fake_punct / (fake_words + 1)),\n",
    "        'proper_density_diff': (real_proper / (real_words + 1)) - (fake_proper / (fake_words + 1)),\n",
    "        \n",
    "        # Variance features\n",
    "        'word_var_diff': real_word_var - fake_word_var,\n",
    "        'word_var_ratio': real_word_var / (fake_word_var + 1e-6),\n",
    "        \n",
    "        # Content features\n",
    "        'numbers_diff': real_numbers - fake_numbers,\n",
    "        'proper_diff': real_proper - fake_proper,\n",
    "    }\n",
    "    \n",
    "    features.append(feature_row)\n",
    "\n",
    "feature_df = pd.DataFrame(features)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buidling the Random Forest Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score: 0.631578947368421\n",
      "CV validation score: 0.5771428571428572\n"
     ]
    }
   ],
   "source": [
    "test_size=0.2\n",
    "random_state=42\n",
    "\n",
    "X = feature_df\n",
    "# Our labels for the real text\n",
    "y = (clean_df['real_file_label'] - 1).values # [1,2] -> [0,1] for modeling \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf.predict(X_test_scaled) \n",
    "\n",
    "print(f\"Training accuracy score: {accuracy_score(y_test, rf_pred)}\")\n",
    "print(f\"CV validation score: {cross_val_score(rf, X_train_scaled, y_train, cv=5).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Music\" Music music music Music music Music mu...</td>\n",
       "      <td>Since its launch on Paranal observatory's Very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>underground exploration on SN's birth has prov...</td>\n",
       "      <td>SN 1987A provides valuable insights as newer o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This research aimed to understand how star sha...</td>\n",
       "      <td>ChromeDriver music player\\nThis study focused ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Using OmegaCAM's wide field capabilities spann...</td>\n",
       "      <td>greek translation :\\nvazhi (megaCAM), territor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AssemblyCulture AssemblyCulture AssemblyCultur...</td>\n",
       "      <td>XClass is software tool that helps astronomers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             file_1  \\\n",
       "0      0  \"Music\" Music music music Music music Music mu...   \n",
       "1      1  underground exploration on SN's birth has prov...   \n",
       "2      2  This research aimed to understand how star sha...   \n",
       "3      3  Using OmegaCAM's wide field capabilities spann...   \n",
       "4      4  AssemblyCulture AssemblyCulture AssemblyCultur...   \n",
       "\n",
       "                                              file_2  \n",
       "0  Since its launch on Paranal observatory's Very...  \n",
       "1  SN 1987A provides valuable insights as newer o...  \n",
       "2  ChromeDriver music player\\nThis study focused ...  \n",
       "3  greek translation :\\nvazhi (megaCAM), territor...  \n",
       "4  XClass is software tool that helps astronomers...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_file = \"../data/test_df.csv\"\n",
    "test_df = pd.read_csv(test_data_file, dtype={'file_1': str, 'file_2': str})\n",
    "test_df.rename(columns={\"Unnamed: 0\": \"index\"}, inplace=True) # Mistake from origin df\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Testing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values\n",
    "test_df['file_1'] = test_df['file_1'].fillna('').astype(str)\n",
    "test_df['file_2'] = test_df['file_2'].fillna('').astype(str)\n",
    "\n",
    "features = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    text1 = row['file_1']\n",
    "    text2 = row['file_2']\n",
    "    \n",
    "    # Basic length features\n",
    "    chars1 = len(text1)\n",
    "    chars2 = len(text2)\n",
    "    words1 = len(text1.split())\n",
    "    words2 = len(text2.split())\n",
    "    \n",
    "    # Basic punctuation features\n",
    "    punct1 = len(re.findall(r'[.!?,:;]', text1))\n",
    "    punct2 = len(re.findall(r'[.!?,:;]', text2))\n",
    "    \n",
    "    # Basic sentence features\n",
    "    sents1 = len([s for s in re.split(r'[.!?]+', text1) if s.strip()])\n",
    "    sents2 = len([s for s in re.split(r'[.!?]+', text2) if s.strip()])\n",
    "    \n",
    "    # Word variance\n",
    "    word_lengths1 = [len(w) for w in text1.split()] if words1 > 0 else [0]\n",
    "    word_lengths2 = [len(w) for w in text2.split()] if words2 > 0 else [0]\n",
    "    word_var1 = np.var(word_lengths1) if len(word_lengths1) > 1 else 0\n",
    "    word_var2 = np.var(word_lengths2) if len(word_lengths2) > 1 else 0\n",
    "    \n",
    "    # Proper nouns\n",
    "    proper1 = len([w for i, w in enumerate(text1.split()) \n",
    "                    if w and w[0].isupper() and i > 0])\n",
    "    proper2 = len([w for i, w in enumerate(text2.split()) \n",
    "                    if w and w[0].isupper() and i > 0])\n",
    "    \n",
    "    # Numbers\n",
    "    numbers1 = len(re.findall(r'\\d+', text1))\n",
    "    numbers2 = len(re.findall(r'\\d+', text2))\n",
    "    \n",
    "    # Create features assuming file_1 is \"real\" and file_2 is \"fake\"\n",
    "    # The model will predict if this assumption is correct\n",
    "    feature_row = {\n",
    "        # Length ratios (file_1 / file_2)\n",
    "        'char_ratio': chars1 / (chars2 + 1),\n",
    "        'word_ratio': words1 / (words2 + 1),\n",
    "        \n",
    "        # Difference features (file_1 - file_2)\n",
    "        'char_diff': chars1 - chars2,\n",
    "        'word_diff': words1 - words2,\n",
    "        'punct_diff': punct1 - punct2,\n",
    "        'sent_diff': sents1 - sents2,\n",
    "        \n",
    "        # Density features\n",
    "        'punct_density_diff': (punct1 / (words1 + 1)) - (punct2 / (words2 + 1)),\n",
    "        'proper_density_diff': (proper1 / (words1 + 1)) - (proper2 / (words2 + 1)),\n",
    "        \n",
    "        # Variance features\n",
    "        'word_var_diff': word_var1 - word_var2,\n",
    "        'word_var_ratio': word_var1 / (word_var2 + 1e-6),\n",
    "        \n",
    "        # Content features\n",
    "        'numbers_diff': numbers1 - numbers2,\n",
    "        'proper_diff': proper1 - proper2,\n",
    "    }\n",
    "    \n",
    "    features.append(feature_row)\n",
    "\n",
    "test_features_df = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Testing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_df = test_features_df[feature_df.columns]\n",
    "\n",
    "# Scale features using fitted scaler\n",
    "test_features_scaled = scaler.transform(test_features_df)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = rf.predict(test_features_scaled)\n",
    "prediction_probabilities = rf.predict_proba(test_features_scaled)\n",
    "\n",
    "final_predictions = pd.DataFrame(predictions + 1)  # Convert [0,1] back to [1,2]\n",
    "final_predictions = final_predictions.rename(columns={'index': 'id', 0: 'real_text_id'})\n",
    "\n",
    "timestamp_str = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "final_predictions.to_csv(f\"../predictions/predictions_rf_{timestamp_str}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
