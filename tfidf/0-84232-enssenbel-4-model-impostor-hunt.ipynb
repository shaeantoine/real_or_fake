{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e86098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T15:31:33.216650Z",
     "iopub.status.busy": "2025-07-09T15:31:33.216376Z",
     "iopub.status.idle": "2025-07-09T15:31:38.704289Z",
     "shell.execute_reply": "2025-07-09T15:31:38.703263Z"
    },
    "id": "sVOu183RSAop",
    "outputId": "fcdf2153-02d7-4823-ed29-01142f56b2d6",
    "papermill": {
     "duration": 5.495822,
     "end_time": "2025-07-09T15:31:38.708675",
     "exception": false,
     "start_time": "2025-07-09T15:31:33.212853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shaemckenna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shaemckenna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7fcf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T15:31:38.716490Z",
     "iopub.status.busy": "2025-07-09T15:31:38.716084Z",
     "iopub.status.idle": "2025-07-09T15:31:38.723731Z",
     "shell.execute_reply": "2025-07-09T15:31:38.723038Z"
    },
    "id": "BHXMpstnSRpt",
    "papermill": {
     "duration": 0.012284,
     "end_time": "2025-07-09T15:31:38.724905",
     "exception": false,
     "start_time": "2025-07-09T15:31:38.712621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir, train_csv_path):\n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    data = []\n",
    "\n",
    "    for _, row in train_df.iterrows():\n",
    "        folder_id = str(row.iloc[0])\n",
    "        real_text_id = str(row.iloc[1])\n",
    "\n",
    "\n",
    "        folder_name = f\"article_{folder_id.zfill(4)}\"\n",
    "        folder_path = os.path.join(data_dir, folder_name)\n",
    "\n",
    "        for file_id in [\"1\", \"2\"]:\n",
    "            file_path = os.path.join(folder_path, f\"file_{file_id}.txt\")\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                    text = f.read().strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                label = 1 if file_id == real_text_id else 0\n",
    "                data.append({'text': text, 'real': label, 'folder': folder_id})\n",
    "\n",
    "            except (FileNotFoundError, UnicodeDecodeError) as e:\n",
    "                print(f\"⚠️ Error loading {file_path}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23520f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T15:31:38.731253Z",
     "iopub.status.busy": "2025-07-09T15:31:38.731018Z",
     "iopub.status.idle": "2025-07-09T15:31:38.735349Z",
     "shell.execute_reply": "2025-07-09T15:31:38.734814Z"
    },
    "id": "_3sNsccOSZ9a",
    "papermill": {
     "duration": 0.008764,
     "end_time": "2025-07-09T15:31:38.736587",
     "exception": false,
     "start_time": "2025-07-09T15:31:38.727823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.punct_table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = text.lower()\n",
    "\n",
    "        text = text.translate(self.punct_table)\n",
    "\n",
    "        tokens = [self.lemmatizer.lemmatize(word)\n",
    "                 for word in text.split()\n",
    "                 if word not in self.stop_words]\n",
    "\n",
    "        return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d6c4b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T15:31:38.742791Z",
     "iopub.status.busy": "2025-07-09T15:31:38.742250Z",
     "iopub.status.idle": "2025-07-09T15:31:38.748177Z",
     "shell.execute_reply": "2025-07-09T15:31:38.747628Z"
    },
    "id": "cKVaJEg0Sc8W",
    "papermill": {
     "duration": 0.009945,
     "end_time": "2025-07-09T15:31:38.749155",
     "exception": false,
     "start_time": "2025-07-09T15:31:38.739210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(df, vectorizer=None, mode='train'):\n",
    "    preprocessor = TextPreprocessor()\n",
    "\n",
    "\n",
    "    df['clean_text'] = df['text'].apply(preprocessor.preprocess)\n",
    "\n",
    "    df['text_length'] = df['text'].apply(len)\n",
    "    df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "    df['avg_word_length'] = df['text'].apply(\n",
    "        lambda x: np.mean([len(w) for w in x.split()]) if len(x.split()) > 0 else 0)\n",
    "\n",
    "    if mode == 'train':\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            ngram_range=(1, 3),\n",
    "            max_features=10000,\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True\n",
    "        )\n",
    "        X_tfidf = vectorizer.fit_transform(df['clean_text'])\n",
    "        return X_tfidf, vectorizer, df\n",
    "    else:\n",
    "        if vectorizer is None:\n",
    "            raise ValueError(\"Vectorizer must be provided for test mode\")\n",
    "        X_tfidf = vectorizer.transform(df['clean_text'])\n",
    "        return X_tfidf, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c403894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T15:31:38.754978Z",
     "iopub.status.busy": "2025-07-09T15:31:38.754775Z",
     "iopub.status.idle": "2025-07-09T15:31:38.762849Z",
     "shell.execute_reply": "2025-07-09T15:31:38.762356Z"
    },
    "id": "fmf45-DTShgp",
    "papermill": {
     "duration": 0.012241,
     "end_time": "2025-07-09T15:31:38.763849",
     "exception": false,
     "start_time": "2025-07-09T15:31:38.751608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_models(X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "    models = {\n",
    "        'LogisticRegression': LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            class_weight='balanced',\n",
    "            C=0.1,\n",
    "            solver='saga',\n",
    "            penalty='elasticnet',\n",
    "            l1_ratio=0.5\n",
    "        ),\n",
    "        'RandomForest': RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            class_weight='balanced_subsample',\n",
    "            random_state=42\n",
    "        ),\n",
    "        'GradientBoosting': GradientBoostingClassifier(\n",
    "            n_estimators=150,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.8,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'SVM': CalibratedClassifierCV(\n",
    "            SVC(\n",
    "                kernel='rbf',\n",
    "                C=1.0,\n",
    "                gamma='scale',\n",
    "                class_weight='balanced',\n",
    "                probability=True\n",
    "            ),\n",
    "            cv=3\n",
    "        )\n",
    "    }\n",
    "\n",
    "    trained_models = {}\n",
    "    val_scores = {}\n",
    "\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        trained_models[name] = model\n",
    "\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, val_preds)\n",
    "        f1 = f1_score(y_val, val_preds)\n",
    "        val_scores[name] = {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "        print(f\"{name} Validation Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
    "        print(classification_report(y_val, val_preds))\n",
    "\n",
    "\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[(name, model) for name, model in trained_models.items()],\n",
    "        voting='soft',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    voting_clf.fit(X_train_res, y_train_res)\n",
    "    trained_models['Ensemble'] = voting_clf\n",
    "\n",
    "\n",
    "    val_preds = voting_clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, val_preds)\n",
    "    f1 = f1_score(y_val, val_preds)\n",
    "    val_scores['Ensemble'] = {'accuracy': acc, 'f1': f1}\n",
    "    print(f\"\\nEnsemble Validation Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
    "    print(classification_report(y_val, val_preds))\n",
    "\n",
    "    return trained_models, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf837e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T15:31:38.769938Z",
     "iopub.status.busy": "2025-07-09T15:31:38.769722Z",
     "iopub.status.idle": "2025-07-09T15:31:38.779608Z",
     "shell.execute_reply": "2025-07-09T15:31:38.779081Z"
    },
    "id": "hxCBlkfqS7wA",
    "papermill": {
     "duration": 0.014205,
     "end_time": "2025-07-09T15:31:38.780593",
     "exception": false,
     "start_time": "2025-07-09T15:31:38.766388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_test(models, val_scores, X_test, test_df):\n",
    "    proba_dfs = []\n",
    "    for name, model in models.items():\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            try:\n",
    "                proba = model.predict_proba(X_test)[:, 1]\n",
    "                proba_dfs.append(pd.DataFrame({\n",
    "                    'folder': test_df['folder'].values,\n",
    "                    'file_id': test_df['file_id'].values,\n",
    "                    f'proba_{name}': proba\n",
    "                }))\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error getting probabilities from {name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    if not proba_dfs:\n",
    "        raise ValueError(\"No probability data was generated from any model\")\n",
    "\n",
    "\n",
    "    proba_df = proba_dfs[0]\n",
    "    for df in proba_dfs[1:]:\n",
    "        proba_df = proba_df.merge(df, on=['folder', 'file_id'])\n",
    "\n",
    "\n",
    "    try:\n",
    "        proba_df['file_number'] = proba_df['file_id'].str.extract(r'file_(\\d+)').astype(int)\n",
    "        proba_df['article_id'] = proba_df['folder'].str.extract(r'article_(\\d+)').astype(int)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error extracting file numbers or article IDs: {str(e)}\")\n",
    "        proba_df['file_number'] = proba_df['file_id'].apply(lambda x: int(x.split('_')[-1]))\n",
    "        proba_df['article_id'] = proba_df.index\n",
    "\n",
    "\n",
    "    best_model = max(val_scores.items(), key=lambda x: x[1]['f1'])[0]\n",
    "\n",
    "    final_selection = []\n",
    "    for article_id in proba_df['article_id'].unique():\n",
    "        try:\n",
    "            article_files = proba_df[proba_df['article_id'] == article_id].copy()\n",
    "\n",
    "            if len(article_files) == 0:\n",
    "                print(f\"⚠️ No files found for article {article_id}\")\n",
    "                continue\n",
    "\n",
    "            article_files['best_model_rank'] = article_files[f'proba_{best_model}'].rank(ascending=False)\n",
    "\n",
    "            proba_cols = [col for col in article_files.columns if col.startswith('proba_')]\n",
    "            article_files['ensemble_proba'] = article_files[proba_cols].mean(axis=1)\n",
    "            article_files['ensemble_rank'] = article_files['ensemble_proba'].rank(ascending=False)\n",
    "\n",
    "            selected = None\n",
    "            try:\n",
    "                best_model_choice = article_files[article_files['best_model_rank'] == 1].iloc[0]\n",
    "\n",
    "                if best_model_choice[f'proba_{best_model}'] > 0.6:\n",
    "                    selected = best_model_choice\n",
    "                else:\n",
    "\n",
    "                    ensemble_choice = article_files[article_files['ensemble_rank'] == 1].iloc[0]\n",
    "                    selected = ensemble_choice\n",
    "            except IndexError:\n",
    "\n",
    "                selected = article_files.iloc[0]\n",
    "                print(f\"⚠️ Used fallback selection for article {article_id}\")\n",
    "\n",
    "            final_selection.append({\n",
    "                'id': int(selected['article_id']),\n",
    "                'real_text_id': int(selected['file_number']),\n",
    "                'confidence': max(selected[f'proba_{best_model}'], selected.get('ensemble_proba', 0))\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing article {article_id}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if not final_selection:\n",
    "        raise ValueError(\"No articles were processed successfully\")\n",
    "\n",
    "    submission_df = pd.DataFrame(final_selection)\n",
    "    return submission_df.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4478eb72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T15:31:38.786419Z",
     "iopub.status.busy": "2025-07-09T15:31:38.786176Z",
     "iopub.status.idle": "2025-07-09T15:32:20.386474Z",
     "shell.execute_reply": "2025-07-09T15:32:20.385578Z"
    },
    "id": "EVbWGUyKTBzZ",
    "outputId": "57ff2a8f-724c-465e-afbf-4e6b36023cef",
    "papermill": {
     "duration": 41.604707,
     "end_time": "2025-07-09T15:32:20.387745",
     "exception": false,
     "start_time": "2025-07-09T15:31:38.783038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Creating features...\n",
      "\n",
      "Training models...\n",
      "\n",
      "Training LogisticRegression...\n",
      "LogisticRegression Validation Accuracy: 0.5000, F1 Score: 0.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        19\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.50        38\n",
      "   macro avg       0.25      0.50      0.33        38\n",
      "weighted avg       0.25      0.50      0.33        38\n",
      "\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest Validation Accuracy: 0.6842, F1 Score: 0.7000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        19\n",
      "           1       0.67      0.74      0.70        19\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.69      0.68      0.68        38\n",
      "weighted avg       0.69      0.68      0.68        38\n",
      "\n",
      "\n",
      "Training GradientBoosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaemckenna/Programs/real_or_fake/rof/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shaemckenna/Programs/real_or_fake/rof/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shaemckenna/Programs/real_or_fake/rof/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting Validation Accuracy: 0.6842, F1 Score: 0.6842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        19\n",
      "           1       0.68      0.68      0.68        19\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.68      0.68      0.68        38\n",
      "weighted avg       0.68      0.68      0.68        38\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "SVM Validation Accuracy: 0.6579, F1 Score: 0.7347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.37      0.52        19\n",
      "           1       0.60      0.95      0.73        19\n",
      "\n",
      "    accuracy                           0.66        38\n",
      "   macro avg       0.74      0.66      0.63        38\n",
      "weighted avg       0.74      0.66      0.63        38\n",
      "\n",
      "\n",
      "Ensemble Validation Accuracy: 0.7105, F1 Score: 0.7179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70        19\n",
      "           1       0.70      0.74      0.72        19\n",
      "\n",
      "    accuracy                           0.71        38\n",
      "   macro avg       0.71      0.71      0.71        38\n",
      "weighted avg       0.71      0.71      0.71        38\n",
      "\n",
      "\n",
      "Making predictions...\n",
      "⚠️ Used fallback selection for article 142\n",
      "\n",
      "✅ Enhanced submission created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_dir = \"../data/train\"\n",
    "    train_csv_path = \"../data/train.csv\"\n",
    "    test_path = \"../data/test\"\n",
    "\n",
    "    print(\"Loading training data...\")\n",
    "    df = load_data(data_dir, train_csv_path)\n",
    "\n",
    "    print(\"Loading test data...\")\n",
    "    test_data = []\n",
    "    for folder in os.listdir(test_path):\n",
    "        folder_path = os.path.join(test_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_id in [\"1\", \"2\"]:\n",
    "                file_path = os.path.join(folder_path, f\"file_{file_id}.txt\")\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                        text = f.read().strip()\n",
    "                    if text:\n",
    "                        test_data.append({'folder': folder, 'file_id': f'file_{file_id}', 'text': text})\n",
    "                except (FileNotFoundError, UnicodeDecodeError) as e:\n",
    "                    print(f\"⚠️ Error loading test file {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    test_df = pd.DataFrame(test_data)\n",
    "\n",
    "\n",
    "    print(\"Creating features...\")\n",
    "    X, vectorizer, df = create_features(df, mode='train')\n",
    "    y = df['real'].astype(int)\n",
    "\n",
    "\n",
    "    if test_df.empty:\n",
    "        print(\"⚠️ Warning: No test data was loaded!\")\n",
    "        submission_df = pd.DataFrame(columns=['id', 'real_text_id'])\n",
    "    else:\n",
    "        X_test, test_df = create_features(test_df, vectorizer=vectorizer, mode='test')\n",
    "\n",
    "        print(\"\\nTraining models...\")\n",
    "        trained_models, val_scores = train_models(X, y)\n",
    "\n",
    "        print(\"\\nMaking predictions...\")\n",
    "        submission_df = predict_test(trained_models, val_scores, X_test, test_df)\n",
    "\n",
    "    submission_df[['id', 'real_text_id']].to_csv(\"submission.csv\", index=False)\n",
    "    print(\"\\n✅ Enhanced submission created: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12964783,
     "sourceId": 105874,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "rof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.449559,
   "end_time": "2025-07-09T15:32:23.008418",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-09T15:31:17.558859",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
