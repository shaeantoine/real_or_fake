{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a Ensemble Model with a TF-IDF Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shaemckenna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shaemckenna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>text</th>\n",
       "      <th>is_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder                                               text  is_real\n",
       "0       0  China\\nThe goal of this project involves achie...        1\n",
       "1       0  The project aims to achieve an accuracy level ...        0\n",
       "2       1  Scientists can learn about how galaxies form a...        0\n",
       "3       1  Dinosaur eggshells offer clues about what dino...        1\n",
       "4       2  China\\nThe study suggests that multiple star s...        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = \"../data/train_long_df.csv\"\n",
    "train_df = pd.read_csv(training_data, dtype={'folder': int, 'text': str, 'is_real': int})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples before data cleaning: 186\n",
      "Number of samples before data cleaning: 184\n"
     ]
    }
   ],
   "source": [
    "clean_df = train_df.copy()\n",
    "print(f\"Number of samples before data cleaning: {len(clean_df)}\")\n",
    "\n",
    "# Removing NA rows altogether \n",
    "clean_df.dropna(subset=[\"text\"], inplace=True)\n",
    "print(f\"Number of samples before data cleaning: {len(clean_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punct_table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(punct_table)\n",
    "    tokens = [lemmatizer.lemmatize(word)\n",
    "                for word in text.split()\n",
    "                if word not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "clean_df['clean_text'] = clean_df['text'].apply(preprocess)\n",
    "clean_df['text_length'] = clean_df['text'].apply(len)\n",
    "clean_df['word_count'] = clean_df['text'].apply(lambda x: len(x.split()))\n",
    "clean_df['avg_word_length'] = clean_df['text'].apply(\n",
    "    lambda x: np.mean([len(w) for w in x.split()]) if len(x.split()) > 0 else 0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=10000,\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(clean_df['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression...\n",
      "LogisticRegression Validation Accuracy: 0.5135, F1 Score: 0.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68        19\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.51        37\n",
      "   macro avg       0.26      0.50      0.34        37\n",
      "weighted avg       0.26      0.51      0.35        37\n",
      "\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest Validation Accuracy: 0.2703, F1 Score: 0.1290\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.42      0.37        19\n",
      "           1       0.15      0.11      0.13        18\n",
      "\n",
      "    accuracy                           0.27        37\n",
      "   macro avg       0.24      0.27      0.25        37\n",
      "weighted avg       0.25      0.27      0.25        37\n",
      "\n",
      "\n",
      "Training GradientBoosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaemckenna/Programs/real_or_fake/rof/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shaemckenna/Programs/real_or_fake/rof/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shaemckenna/Programs/real_or_fake/rof/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting Validation Accuracy: 0.3784, F1 Score: 0.3030\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.47      0.44        19\n",
      "           1       0.33      0.28      0.30        18\n",
      "\n",
      "    accuracy                           0.38        37\n",
      "   macro avg       0.37      0.38      0.37        37\n",
      "weighted avg       0.37      0.38      0.37        37\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "SVM Validation Accuracy: 0.7297, F1 Score: 0.7727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.53      0.67        19\n",
      "           1       0.65      0.94      0.77        18\n",
      "\n",
      "    accuracy                           0.73        37\n",
      "   macro avg       0.78      0.74      0.72        37\n",
      "weighted avg       0.78      0.73      0.72        37\n",
      "\n",
      "\n",
      "Ensemble Validation Accuracy: 0.3243, F1 Score: 0.2424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.42      0.39        19\n",
      "           1       0.27      0.22      0.24        18\n",
      "\n",
      "    accuracy                           0.32        37\n",
      "   macro avg       0.32      0.32      0.32        37\n",
      "weighted avg       0.32      0.32      0.32        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_tfidf\n",
    "y = clean_df[\"is_real\"].astype(int)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        C=0.1,\n",
    "        solver='saga',\n",
    "        penalty='elasticnet',\n",
    "        l1_ratio=0.5\n",
    "    ),\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'SVM': CalibratedClassifierCV(\n",
    "        SVC(\n",
    "            kernel='rbf',\n",
    "            C=1.0,\n",
    "            gamma='scale',\n",
    "            class_weight='balanced',\n",
    "            probability=True\n",
    "        ),\n",
    "        cv=3\n",
    "    )\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "val_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    trained_models[name] = model\n",
    "\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, val_preds)\n",
    "    f1 = f1_score(y_val, val_preds)\n",
    "    val_scores[name] = {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "    print(f\"{name} Validation Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
    "    print(classification_report(y_val, val_preds))\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(name, model) for name, model in trained_models.items()],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "voting_clf.fit(X_train_res, y_train_res)\n",
    "trained_models['Ensemble'] = voting_clf\n",
    "\n",
    "\n",
    "val_preds = voting_clf.predict(X_val)\n",
    "acc = accuracy_score(y_val, val_preds)\n",
    "f1 = f1_score(y_val, val_preds)\n",
    "val_scores['Ensemble'] = {'accuracy': acc, 'f1': f1}\n",
    "print(f\"\\nEnsemble Validation Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
    "print(classification_report(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
